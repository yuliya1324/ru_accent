# Руководство по рабочему процессу ru_accent_poet

Этот документ предоставляет подробное объяснение того, как работает процесс расстановки ударений в русском тексте в пакете ru_accent_poet.

## Обзор

Пакет ru_accent_poet использует гибридный подход для добавления знаков ударения в русский текст, объединяя:
1. Подход на основе словаря/правил
2. Подход на основе нейронной сети

Этот гибридный метод обеспечивает высокую точность для широкого спектра русских слов, включая те, которые могут отсутствовать в словарях.

## Этапы рабочего процесса

### 1. Обработка текста

Когда вы вызываете `accent_line()` со строкой русского текста, происходит следующее:

```python
from ru_accent_poet import accent_line
accented_text = accent_line("Мой дядя самых честных правил")
```

Функция:
1. Разбивает входной текст на отдельные слова
2. Обрабатывает каждое слово отдельно
3. Объединяет слова со знаками ударения

### 2. Обработка на основе правил

Для каждого слова пакет сначала пытается применить правила на основе словаря:

```python
words_rule = accent_line_rules(line).split()
```

Функция `accent_line_rules()`:
1. Использует файлы словарей `accent.dic` и `accent1.dic`, содержащие более 1 миллиона русских слов с правильными знаками ударения
2. Ищет каждое слово в словаре
3. Возвращает слово со знаками ударения, если оно найдено
4. Может возвращать несколько знаков ударения для одного слова (для слов с альтернативными произношениями)

### 3. Обработка нейронной сетью

Параллельно к каждому слову применяется модель нейронной сети:

```python
words_nacc = accent.put_stress(line).split()
```

Нейронный подход:
1. Использует двунаправленную LSTM-модель, обученную на русском тексте
2. Предсказывает наиболее вероятную позицию для знака ударения
3. Всегда возвращает ровно один знак ударения на слово (если в слове есть гласные)

### 4. Логика принятия решений

Для каждого слова пакет решает, какой результат использовать, на основе определенных критериев:

```python
if (len(re.findall("'", words_rule[j])) > 1) or \
   ("'" not in words_rule[j] and not re.findall('[ёЁ]', words_rule[j])) or \
   ("'" in words_rule[j] and re.findall('[ёЁ]', words_rule[j])):
    words[j] = words_nacc[j]  # Использовать результат нейронной сети
else:
    words[j] = words_rule[j]  # Использовать результат словаря
```

Результат нейронной сети используется, когда:
1. Словарь возвращает несколько знаков ударения для слова
2. Словарь не предоставляет никаких знаков ударения для слова
3. Есть несоответствие с буквой 'ё' (которая уже подразумевает ударение)

В противном случае используется результат словаря.

### 5. Особые случаи

Пакет обрабатывает несколько особых случаев:
1. Слова с одной гласной (ударение не требуется)
2. Слова, содержащие букву 'ё' (уже подразумевает ударение)
3. Короткие предлоги и частицы, такие как 'обо', 'изо', 'подо', 'нибудь'
4. Слова, отсутствующие в словаре, обрабатываются нейронной сетью

## Использование в командной строке

Пакет можно использовать для обработки целых файлов:

```bash
python -m ru_accent_poet file1.txt file2.txt
```

Это создает новые файлы с добавлением `.accented.` к имени файла, содержащие исходный текст с добавленными знаками ударения.

## Программное использование

```python
# Обработка одной строки
from ru_accent_poet import accent_line
result = accent_line("Мой дядя самых честных правил")
print(result)  # Выводит: "Мой дя'дя са'мых че'стных пра'вил"

# Обработка файлов
from ru_accent_poet import write_file
write_file(["file1.txt", "file2.txt"])

# Использование только подхода на основе нейронной сети
from ru_accent_poet.neuro import accent_neuro
accent_neuro(["file1.txt"])  # Создает файлы с расширением .nacc.

# Использование только подхода на основе словаря
from ru_accent_poet.rules import accent_rules
accent_rules(["file1.txt"])  # Создает файлы с расширением .acc.
```

## Техническая реализация

1. Словарный подход использует структуру на основе префиксного дерева (trie) для эффективного поиска слов
2. Нейронная сеть — это двунаправленная LSTM-модель, обученная на большом корпусе русской поэзии
3. Реализация TensorFlow/Keras была обновлена для работы с современными версиями (TensorFlow 2.15+ и Keras 3.x)
4. Пакет включает пользовательскую патченную версию класса Accent из пакета russtress для обеспечения совместимости

## Обработка ошибок и граничных случаев

Пакет обрабатывает несколько граничных случаев:
1. Слова, отсутствующие в словаре
2. Иностранные слова, написанные кириллицей
3. Имена собственные и редкие слова
4. Слова с несколькими возможными позициями ударения

Благодаря сочетанию подходов на основе словаря и нейронной сети, пакет обеспечивает надежную расстановку ударений даже для сложных или неоднозначных случаев.

## Расширение пакета

Вы можете расширить пакет путем:
1. Добавления большего количества слов в файлы словарей
2. Повторного обучения нейронной модели на специализированном тексте
3. Изменения логики принятия решений, чтобы отдавать предпочтение одному подходу перед другим

Для большинства пользователей гибридный подход по умолчанию предлагает лучший баланс точности и охвата.